---
title: "Homework 5"
author: "Youssra Yemmas"
date: "2023-11-12"
output: github_document
---

```{r setup, include=FALSE}
library(knitr)
library(tidyverse)
library(broom)
library(rvest)


set.seed(1)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = 6,
  out.width = "90%"
  )

theme_set(theme_minimal())

options(
  ggplot2.continuous.color = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1


For the city of Baltimore, MD, use the prop.test function to estimate the proportion of homicides that are unsolved; save the output of prop.test as an R object, apply the broom::tidy to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.

Now run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Do this within a “tidy” pipeline, making use of purrr::map, purrr::map2, list columns and unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.

Create a plot that shows the estimates and CIs for each city – check out geom_errorbar for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.

```{r}
# first I need to read in the data from the csv file or from the github repo. It does not read correctly from the csv file so I used the github.
wp_homicide_df =
  read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")
head(wp_homicide_df)
nrow(wp_homicide_df)
ncol(wp_homicide_df)


```

The raw data has 52179 observations of 12 variables.

# Tidying the data, creating a city_state variable and two data frames one that summarises total homicides and one that summarises unsolved homicides 
```{r}
wp_homicide_tidied = 
  wp_homicide_df %>% 
  mutate(
    city_state = str_c(city, state, sep = ", ")
  ) %>% 
  filter(!city_state == "Tulsa, AL")

homicide_sum = 
  wp_homicide_tidied %>% 
  group_by(city_state) %>% 
  summarize(
    total_homicides = n())

homicide_sum %>% 
  knitr::kable()

unsolved_homicide_sum =
  wp_homicide_tidied %>% 
  filter(disposition %in% c("Closed without arrest", "Open/No arrest")) %>% 
  group_by(city_state) %>% 
  summarize(
    total_unsolved = n())

unsolved_homicide_sum %>% 
  knitr::kable()
#why is there only one homicide for Tusla, AL? Maybe I should remove it from the dataset because I can see from googling it that there is no such city as Tulsa in Alabama. Or should I try to include it in the Tulsa, OK dataset because from the lat and lon it seems to be in that city. I think I am just going to remove it.
```

## Problem 1 cont.

```{r}
# using the 'r prop.test' function to estimate the proportion of homicides that are unsolved in the city_state of Baltimore, MD

homicide_prop_test = function(x) {
  
  n_hom =
    homicide_sum %>% 
    filter(city_state == x) %>% 
    pull(total_homicides)
  
  n_un =
    unsolved_homicide_sum %>% 
    filter(city_state == x) %>% 
    pull(total_unsolved)
  
  result = broom::tidy(prop.test(x = n_un, n_hom))
  
}

print(homicide_prop_test("Baltimore, MD"))

```

